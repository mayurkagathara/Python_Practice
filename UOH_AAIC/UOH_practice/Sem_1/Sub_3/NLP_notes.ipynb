{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Stemming vs lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "source": [
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#list of tokenized words\n",
    "words = ['cared','university','mice','easily','singing',\n",
    "\t'language','corpora','singer','sportingly','rocks']\n",
    "\n",
    "#stem's of each word\n",
    "stem_words_snowball = []\n",
    "stem_words_porter = []\n",
    "stem_words_lemma = []"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "  xs = snow_stemmer.stem(w)\n",
    "  xp = porter_stemmer.stem(w)\n",
    "  xl = lemmatizer.lemmatize(w)\n",
    "  \n",
    "  stem_words_snowball.append(xs)\n",
    "  stem_words_porter.append(xp)\n",
    "  stem_words_lemma.append(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "word           snow_ball      porter         lemma          \n------------------------------------------------------------\ncared          care           care           cared          \nuniversity     univers        univers        university     \nmice           mice           mice           mouse          \neasily         easili         easili         easily         \nsinging        sing           sing           singing        \nlanguage       languag        languag        language       \ncorpora        corpora        corpora        corpus         \nsinger         singer         singer         singer         \nsportingly     sport          sportingli     sportingly     \nrocks          rock           rock           rock           \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'word':15}{'snow_ball':15}{'porter':15}{'lemma':15}\")\n",
    "print('-'*60)\n",
    "for word,snow_ball,porter,lemma in zip(words,stem_words_snowball,stem_words_porter,stem_words_lemma):\n",
    "  print(f\"{word:15}{snow_ball:15}{porter:15}{lemma:15}\")"
   ]
  },
  {
   "source": [
    "### Bag of Words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}